{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e423e18",
   "metadata": {},
   "source": [
    "# Book Recommender System \n",
    "\n",
    "## 狄豪飛 111550196  ## 邱倫恩 111550195 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f44e7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         isbn                                 Book-Title  \\\n",
       " 0  0312874278                 Through Wolf's Eyes (Wolf)   \n",
       " 1  084394899X                               Eagle Dancer   \n",
       " 2  0505524481        Across a Moonswept Moor (Timeswept)   \n",
       " 3  0449005887                               The Last Man   \n",
       " 4  1879941066  Georgia Scenes (Southern Classics Series)   \n",
       " \n",
       "                    Book-Author Year-Of-Publication  \\\n",
       " 0               Jane Lindskold                2001   \n",
       " 1                Theresa Scott                2001   \n",
       " 2                Julie Moffett                2001   \n",
       " 3               Charles Kenney                2001   \n",
       " 4  Augustus Baldwin Longstreet                1992   \n",
       " \n",
       "                        publisher  \\\n",
       " 0                      Tor Books   \n",
       " 1                  Leisure Books   \n",
       " 2  Dorchester Publishing Company   \n",
       " 3               Ballantine Books   \n",
       " 4      J. S. Sanders and Company   \n",
       " \n",
       "                                          Image-URL-S  \\\n",
       " 0  http://images.amazon.com/images/P/0312874278.0...   \n",
       " 1  http://images.amazon.com/images/P/084394899X.0...   \n",
       " 2  http://images.amazon.com/images/P/0505524481.0...   \n",
       " 3  http://images.amazon.com/images/P/0449005887.0...   \n",
       " 4  http://images.amazon.com/images/P/1879941066.0...   \n",
       " \n",
       "                                          Image-URL-M  \\\n",
       " 0  http://images.amazon.com/images/P/0312874278.0...   \n",
       " 1  http://images.amazon.com/images/P/084394899X.0...   \n",
       " 2  http://images.amazon.com/images/P/0505524481.0...   \n",
       " 3  http://images.amazon.com/images/P/0449005887.0...   \n",
       " 4  http://images.amazon.com/images/P/1879941066.0...   \n",
       " \n",
       "                                          Image-URL-L  \n",
       " 0  http://images.amazon.com/images/P/0312874278.0...  \n",
       " 1  http://images.amazon.com/images/P/084394899X.0...  \n",
       " 2  http://images.amazon.com/images/P/0505524481.0...  \n",
       " 3  http://images.amazon.com/images/P/0449005887.0...  \n",
       " 4  http://images.amazon.com/images/P/1879941066.0...  ,\n",
       "    User-ID                            location   age\n",
       " 0        1                  nyc, new york, usa   NaN\n",
       " 1        2           stockton, california, usa  18.0\n",
       " 2        3     moscow, yukon territory, russia   NaN\n",
       " 3        4           porto, v.n.gaia, portugal  17.0\n",
       " 4        5  farnborough, hants, united kingdom   NaN,\n",
       "    User-ID        isbn  Book-Rating\n",
       " 0    67609  0553269224          0.0\n",
       " 1    67609  0804108692          0.0\n",
       " 2    67615  0553075624         10.0\n",
       " 3    67615  0618131736          7.0\n",
       " 4    67619  0679813438          8.0,\n",
       " '(psycopg2.OperationalError) could not translate host name \"booksdatabase.c1esdou4ahe.us-east-1.rds.amazonaws.com\" to address: No such host is known. \\n\\n(Background on this error at: https://sqlalche.me/e/14/e3q8)')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load the datasets\n",
    "books_path = 'Books.csv'\n",
    "users_path = 'Users.csv'\n",
    "ratings_path = 'Ratings.csv'\n",
    "\n",
    "# Database connection parameters\n",
    "db_endpoint = \"booksdatabase.cae1sdou4ahe.us-east-1.rds.amazonaws.com\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"postgres\"  # Replace with your actual database name\n",
    "db_user = \"postgres\"\n",
    "db_password = \"12345678\"\n",
    "\n",
    "# Create a connection URL\n",
    "conn_url = f\"postgresql://{db_user}:{db_password}@{db_endpoint}:{db_port}/{db_name}\"\n",
    "\n",
    "# Create an engine to manage the connection\n",
    "engine = create_engine(conn_url)\n",
    "\n",
    "try:\n",
    "    # Replace your pd.read_csv() calls with pd.read_sql() calls\n",
    "    books_df = pd.read_sql(\"SELECT * FROM books\", engine)\n",
    "    users_df = pd.read_sql(\"SELECT * FROM users\", engine)\n",
    "    ratings_df = pd.read_sql(\"SELECT * FROM ratings\", engine)\n",
    "\n",
    "    # Display the first few rows of each dataset\n",
    "    books_head = books_df.head()\n",
    "    users_head = users_df.head()\n",
    "    ratings_head = ratings_df.head()\n",
    "except Exception as e:\n",
    "    error_message = str(e)\n",
    "\n",
    "books_head, users_head, ratings_head, error_message if 'error_message' in locals() else \"No errors\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce8b7f",
   "metadata": {},
   "source": [
    "### Book dataset (Books.csv):\n",
    "\n",
    "#### Columns: ISBN, Book-Title, Book-Author, Year-Of-Publication, Publisher, Image-URL-S, Image-URL-M, Image-URL-L.\n",
    "First Lines:\n",
    "ISBN: 0195153448, Book-Title: Classical Mythology, Author: Mark P. O. Morford, etc.\n",
    "Note: Some columns, such as Year-Of-Publication, appear to have mixed data types.\n",
    "\n",
    "### User data set (Users.csv):\n",
    "\n",
    "#### Columns: User-ID, Location, Age.\n",
    "First Rows:\n",
    "User-ID: 1, Location: nyc, new york, usa, Age: NaN, etc.\n",
    "Note: The Age column contains missing values (NaN).\n",
    "\n",
    "### Ratings Dataset (Ratings.csv):\n",
    "\n",
    "#### Columns: User-ID, ISBN, Book-Rating.\n",
    "First Rows:\n",
    "User-ID: 276725, ISBN: 034545104X, Book-Rating: 0, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b749bac",
   "metadata": {},
   "source": [
    "## Let's proceed with cleaning and preparing the data. This process involves handling missing values, outliers, and normalizing formats. I'll address each dataset separately:\n",
    "\n",
    "### Books Dataset:\n",
    "\n",
    "Handle mixed data types in Year-Of-Publication.\n",
    "Verify and clean publisher and author fields.\n",
    "Exclude books with insufficient information.\n",
    "Users Dataset:\n",
    "\n",
    "Handle missing values in Age.\n",
    "Normalize the Location field, if necessary.\n",
    "Ratings Dataset:\n",
    "\n",
    "Validate the ISBN references to ensure they match with the books dataset.\n",
    "Check for any anomalies in the Book-Rating field.\n",
    "I'll start with the books dataset, focusing on the Year-Of-Publication field. Let's clean and transform this data first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc56c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(isbn                      0\n",
       " Book-Title                0\n",
       " Book-Author               1\n",
       " Year-Of-Publication    4635\n",
       " publisher                 2\n",
       " Image-URL-S               0\n",
       " Image-URL-M               0\n",
       " Image-URL-L               3\n",
       " dtype: int64,\n",
       "          isbn                                 Book-Title  \\\n",
       " 0  0312874278                 Through Wolf's Eyes (Wolf)   \n",
       " 1  084394899X                               Eagle Dancer   \n",
       " 2  0505524481        Across a Moonswept Moor (Timeswept)   \n",
       " 3  0449005887                               The Last Man   \n",
       " 4  1879941066  Georgia Scenes (Southern Classics Series)   \n",
       " \n",
       "                    Book-Author  Year-Of-Publication  \\\n",
       " 0               Jane Lindskold               2001.0   \n",
       " 1                Theresa Scott               2001.0   \n",
       " 2                Julie Moffett               2001.0   \n",
       " 3               Charles Kenney               2001.0   \n",
       " 4  Augustus Baldwin Longstreet               1992.0   \n",
       " \n",
       "                        publisher  \\\n",
       " 0                      Tor Books   \n",
       " 1                  Leisure Books   \n",
       " 2  Dorchester Publishing Company   \n",
       " 3               Ballantine Books   \n",
       " 4      J. S. Sanders and Company   \n",
       " \n",
       "                                          Image-URL-S  \\\n",
       " 0  http://images.amazon.com/images/P/0312874278.0...   \n",
       " 1  http://images.amazon.com/images/P/084394899X.0...   \n",
       " 2  http://images.amazon.com/images/P/0505524481.0...   \n",
       " 3  http://images.amazon.com/images/P/0449005887.0...   \n",
       " 4  http://images.amazon.com/images/P/1879941066.0...   \n",
       " \n",
       "                                          Image-URL-M  \\\n",
       " 0  http://images.amazon.com/images/P/0312874278.0...   \n",
       " 1  http://images.amazon.com/images/P/084394899X.0...   \n",
       " 2  http://images.amazon.com/images/P/0505524481.0...   \n",
       " 3  http://images.amazon.com/images/P/0449005887.0...   \n",
       " 4  http://images.amazon.com/images/P/1879941066.0...   \n",
       " \n",
       "                                          Image-URL-L  \n",
       " 0  http://images.amazon.com/images/P/0312874278.0...  \n",
       " 1  http://images.amazon.com/images/P/084394899X.0...  \n",
       " 2  http://images.amazon.com/images/P/0505524481.0...  \n",
       " 3  http://images.amazon.com/images/P/0449005887.0...  \n",
       " 4  http://images.amazon.com/images/P/1879941066.0...  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the Books Dataset\n",
    "\n",
    "# Convert Year-Of-Publication to numeric, set errors to NaN\n",
    "books_df['Year-Of-Publication'] = pd.to_numeric(books_df['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Replace invalid years with NaN (e.g., years in the future or too far in the past)\n",
    "current_year = pd.Timestamp.now().year\n",
    "books_df.loc[(books_df['Year-Of-Publication'] > current_year) | (books_df['Year-Of-Publication'] < 1800), 'Year-Of-Publication'] = None\n",
    "\n",
    "# Check for missing values in important columns\n",
    "missing_values_books = books_df.isnull().sum()\n",
    "\n",
    "# Drop rows where important information is missing\n",
    "books_df_cleaned = books_df.dropna(subset=['Book-Title', 'Book-Author', 'Year-Of-Publication', 'publisher'])\n",
    "\n",
    "missing_values_books, books_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a0c6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(User-ID          0\n",
       " location         0\n",
       " age         112010\n",
       " dtype: int64,\n",
       "    User-ID                            location   age\n",
       " 0        1                  nyc, new york, usa   NaN\n",
       " 1        2           stockton, california, usa  18.0\n",
       " 2        3     moscow, yukon territory, russia   NaN\n",
       " 3        4           porto, v.n.gaia, portugal  17.0\n",
       " 4        5  farnborough, hants, united kingdom   NaN)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the Users Dataset\n",
    "\n",
    "# Handling missing values in 'Age'\n",
    "# Replace invalid ages (e.g., less than 5 and greater than 100) with NaN\n",
    "users_df['age'] = users_df['age'].apply(lambda x: x if 5 <= x <= 100 else None)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values_users = users_df.isnull().sum()\n",
    "\n",
    "# For this example, we'll leave the NaN values as is, as imputation might not be accurate\n",
    "# and removing all rows with missing ages could significantly reduce the dataset size\n",
    "\n",
    "# Normalizing the 'Location' field is optional and can be complex. \n",
    "# It might involve parsing the location string and standardizing it.\n",
    "# For simplicity, we'll leave it as is for now.\n",
    "\n",
    "missing_values_users, users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b707ad8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(User-ID        0\n",
       " isbn           0\n",
       " Book-Rating    0\n",
       " dtype: int64,\n",
       " (1017065, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the Ratings Dataset\n",
    "\n",
    "# Validate the ISBN references\n",
    "# Keep only those ratings where the ISBN exists in the books dataset\n",
    "ratings_df_cleaned = ratings_df[ratings_df['isbn'].isin(books_df_cleaned['isbn'])]\n",
    "\n",
    "# Check for any anomalies in the 'Book-Rating' field\n",
    "# Assuming ratings should be within a specific range (e.g., 0-10)\n",
    "ratings_df_cleaned = ratings_df_cleaned[(ratings_df_cleaned['Book-Rating'] >= 0) & (ratings_df_cleaned['Book-Rating'] <= 10)]\n",
    "\n",
    "# Check for missing values and the size of the cleaned dataset\n",
    "missing_values_ratings = ratings_df_cleaned.isnull().sum()\n",
    "cleaned_ratings_size = ratings_df_cleaned.shape\n",
    "\n",
    "missing_values_ratings, cleaned_ratings_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f037e6b",
   "metadata": {},
   "source": [
    "### The cleaning of the Books dataset has been completed with the following steps:\n",
    "\n",
    "- Converted Year-Of-Publication to numeric, setting non-numeric values to NaN.\n",
    "- Replaced invalid years (those in the future or before 1800) with NaN.\n",
    "- Checked for missing values in key columns (Book-Author, Year-Of-Publication, Publisher). We found:\n",
    "- Book-Author: 1 missing value\n",
    "- Year-Of-Publication: 4,635 missing values\n",
    "- Publisher: 2 missing values\n",
    "- Dropped rows with missing values in these critical columns.\n",
    "\n",
    "### The cleaning of the Users dataset has been done with these steps:\n",
    "\n",
    "- Invalid ages (less than 5 or greater than 100) have been replaced with NaN.\n",
    "- There are 112,010 missing values in the Age field.\n",
    "- We chose not to impute ages due to potential inaccuracies, and because removing all rows with missing ages could significantly reduce the dataset.\n",
    "- The Location field has been left as is for now, as normalization can be complex and may not be crucial for the recommendation system.\n",
    "\n",
    "Then, we clean the Ratings dataset. This involves validating ISBN references against the books dataset and checking for anomalies in the Book-Rating field. Let's proceed with that.\n",
    "\n",
    "### The cleaning of the Ratings dataset has been completed with the following steps:\n",
    "\n",
    "- Validated ISBN references, ensuring all ratings correspond to books present in the cleaned Books dataset.\n",
    "- Checked for anomalies in Book-Rating, confirming all ratings are within the expected range (0-10).\n",
    "- No missing values were found in the cleaned Ratings dataset.\n",
    "- The size of the cleaned Ratings dataset is 1,017,065 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77702a7a",
   "metadata": {},
   "source": [
    "# Developing the Recommendation Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c5cf8",
   "metadata": {},
   "source": [
    "In our book recommendation system, we're employing a method known as Collaborative Filtering (CF). This technique makes automatic predictions (filtering) about the interests of a user by collecting preferences from many users (collaborating). The underlying assumption of CF is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a random person.\n",
    "\n",
    "##### Collaborative Filtering Overview:\n",
    "\n",
    "- #### User-Item Interactions: \n",
    "Our model is based on user-item interactions, which in our case are the book ratings given by users. We don't need any information about the books or the users themselves (like book genres or user demographics) — we only need to know who rated what and how much they liked it.\n",
    "\n",
    "- #### Similarity of Preferences:\n",
    "The core idea is to find users who have similar rating patterns. If user A rates books X and Y highly, and user B does the same, then we can infer they have similar tastes. If user A has rated book Z highly, but user B hasn't rated it yet, we might predict that user B will also like book Z.\n",
    "\n",
    "- #### Matrix of Ratings: \n",
    "We arrange our data into a matrix where each row represents a user and each column represents a book. The entries of this matrix are the ratings that users have given to books.\n",
    "\n",
    "##### Here’s how our model works:\n",
    "\n",
    "- #### Data Matrix: \n",
    "We start with a matrix where each row corresponds to a user, and each column corresponds to an item (in our case, books). The matrix entries are the ratings users have given to the books.\n",
    "\n",
    "- #### Similarity Assessment: \n",
    "The model looks for similarities between users based on their ratings. If two users have rated a set of books similarly, the model infers that they have similar tastes.\n",
    "\n",
    "- #### Predicting Ratings:\n",
    "For a given user, the model predicts how they would rate books they haven't yet interacted with by aggregating the ratings of similar users. These predictions are based on the weighted average of the ratings from similar users, adjusted for the active user's overall rating behavior.\n",
    "\n",
    "##### When we say 'Matrix Factorization', we're referring to:\n",
    "\n",
    "- #### Matrix Decomposition:\n",
    "This is a process where the original large matrix of user-item interactions is decomposed into two or more smaller matrices. The goal is to capture the underlying structure in the user-item matrix.\n",
    "\n",
    "- #### Latent Factors:\n",
    "These smaller matrices represent latent factors - hidden characteristics that might determine how a user rates an item. For books, latent factors could include genres or themes that are not explicitly labeled but can be inferred from user ratings.\n",
    "\n",
    "- #### Learning and Optimization:\n",
    "The model learns these latent factors by minimizing the difference between the observed ratings in the user-item matrix and the product of the latent factor matrices. Techniques like Stochastic Gradient Descent (SGD) or Alternating Least Squares (ALS) can be used for this optimization task.\n",
    "\n",
    "- #### Prediction:\n",
    "Once the model has learned these latent factors, it can predict a rating for a user-item pair where the rating was not previously known. It does this by taking the dot product of the latent factors for the user and the item.\n",
    "\n",
    "- #### Recommendations:\n",
    "Finally, the model can recommend items to a user by selecting items with the highest predicted ratings that the user has not yet rated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a72823",
   "metadata": {},
   "source": [
    "### Step 1: Filter the Data\n",
    "\n",
    "#### First, we need to filter the data according to the criteria:\n",
    "\n",
    "* Include only users who have rated at least 50 books.\n",
    "* Include only books that have been rated by at least 50 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76ba7bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98178, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reattempting Step 1: Filter the Data\n",
    "\n",
    "# Filtering users who have rated at least 50 books\n",
    "users_with_50_ratings = ratings_df_cleaned['User-ID'].value_counts()\n",
    "users_with_50_ratings = users_with_50_ratings[users_with_50_ratings >= 50].index.tolist()\n",
    "\n",
    "filtered_ratings = ratings_df_cleaned[ratings_df_cleaned['User-ID'].isin(users_with_50_ratings)]\n",
    "\n",
    "# Filtering books that have been rated by at least 50 users\n",
    "books_with_50_ratings = filtered_ratings['isbn'].value_counts()\n",
    "books_with_50_ratings = books_with_50_ratings[books_with_50_ratings >= 50].index.tolist()\n",
    "\n",
    "filtered_ratings = filtered_ratings[filtered_ratings['isbn'].isin(books_with_50_ratings)]\n",
    "\n",
    "# Checking the shape of the filtered ratings dataset\n",
    "filtered_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429155a0",
   "metadata": {},
   "source": [
    "### Step 2: Build the Item Similarity Matrix\n",
    "\n",
    "We will calculate the similarity between items (books) using the user ratings. Commonly used methods for similarity include cosine similarity, Pearson correlation, or Jaccard similarity. We'll select one based on the nature of our dataset.\n",
    "\n",
    "The Item Similarity Matrix has been successfully built using cosine similarity. This matrix represents the similarity between each pair of books based on user ratings. In the matrix, each row and column correspond to a book's ISBN, and the values represent the similarity score between books.\n",
    "\n",
    "The portion displayed shows the similarity scores for the first five books. A score of 1 indicates identical ratings patterns, while a score of 0 indicates no similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2377cded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>isbn</th>\n",
       "      <th>002026478X</th>\n",
       "      <th>002542730X</th>\n",
       "      <th>0060008032</th>\n",
       "      <th>0060085444</th>\n",
       "      <th>0060096195</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002026478X</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002542730X</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060008032</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054638</td>\n",
       "      <td>0.039401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060085444</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060096195</th>\n",
       "      <td>0.099748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039401</td>\n",
       "      <td>0.044737</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "isbn        002026478X  002542730X  0060008032  0060085444  0060096195\n",
       "isbn                                                                  \n",
       "002026478X    1.000000    0.000000    0.000000    0.000000    0.099748\n",
       "002542730X    0.000000    1.000000    0.028303    0.000000    0.000000\n",
       "0060008032    0.000000    0.028303    1.000000    0.054638    0.039401\n",
       "0060085444    0.000000    0.000000    0.054638    1.000000    0.044737\n",
       "0060096195    0.099748    0.000000    0.039401    0.044737    1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Creating a pivot table for the similarity matrix\n",
    "pivot_table = filtered_ratings.pivot_table(index='isbn', columns='User-ID', values='Book-Rating').fillna(0)\n",
    "\n",
    "# Calculating cosine similarity between items (books)\n",
    "cosine_sim = cosine_similarity(pivot_table)\n",
    "\n",
    "# Creating a DataFrame for the similarity matrix for better readability\n",
    "similarity_matrix = pd.DataFrame(cosine_sim, index=pivot_table.index, columns=pivot_table.index)\n",
    "\n",
    "# Displaying a portion of the similarity matrix\n",
    "similarity_matrix.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4dfc2",
   "metadata": {},
   "source": [
    "### Step 3: Generating Book Recommendations\n",
    "##### In this step, we'll use the Item Similarity Matrix to generate book recommendations. \n",
    "\n",
    "#### The process involves:\n",
    "\n",
    "* #### Selecting a book as input (either randomly or based on a specific ISBN).\n",
    "* #### Finding similar books based on the similarity matrix.\n",
    "* #### Ranking these similar books to recommend the most similar ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85aa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_title(isbn, books_df):\n",
    "    \"\"\" Get the book title given an ISBN. \"\"\"\n",
    "    title = books_df.loc[books_df['isbn'] == isbn, 'Book-Title'].iloc[0]\n",
    "    return title\n",
    "\n",
    "def recommend_books(isbn, similarity_matrix, books_df, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend books based on a given ISBN using the item similarity matrix.\n",
    "    \"\"\"\n",
    "    # Retrieve similar books\n",
    "    similar_books = similarity_matrix[isbn].sort_values(ascending=False)\n",
    "\n",
    "    # Remove the book itself from the recommendation\n",
    "    similar_books = similar_books[similar_books.index != isbn]\n",
    "\n",
    "    # Get the top N similar books\n",
    "    top_similar_books = similar_books.head(num_recommendations).index.tolist()\n",
    "\n",
    "    # Get book titles\n",
    "    recommended_books = [get_book_title(book_isbn, books_df) for book_isbn in top_similar_books]\n",
    "\n",
    "    return recommended_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7815a22",
   "metadata": {},
   "source": [
    "### I'll demonstrate this by choosing a book from our dataset and then generating recommendations based on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac4d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Rising Tides',\n",
       " ['Inner Harbor (Quinn Brothers (Paperback))',\n",
       "  'Sea Swept (Quinn Brothers (Paperback))',\n",
       "  'Heart of the Sea (Irish Trilogy)',\n",
       "  'Tears of the Moon (Irish Trilogy)',\n",
       "  'Jewels of the Sun (Irish Trilogy)'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Choose a random ISBN from the dataset to use as input\n",
    "input_isbn = filtered_ratings['isbn'].sample().iloc[0]\n",
    "input_book_title = get_book_title(input_isbn, books_df_cleaned)\n",
    "\n",
    "# Generate recommendations\n",
    "recommended_books = recommend_books(input_isbn, similarity_matrix, books_df_cleaned)\n",
    "\n",
    "input_book_title, recommended_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ce32b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_info(isbn, books_df):\n",
    "    \"\"\" Get the book title and image URL given an ISBN. \"\"\"\n",
    "    book_info = books_df.loc[books_df['ISBN'] == isbn, ['Book-Title', 'Image-URL-L']].iloc[0]\n",
    "    return book_info\n",
    "\n",
    "def recommend_books_with_images(isbn, similarity_matrix, books_df, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend books based on a given ISBN using the item similarity matrix,\n",
    "    and include their images.\n",
    "    \"\"\"\n",
    "    # Retrieve similar books\n",
    "    similar_books = similarity_matrix[isbn].sort_values(ascending=False)\n",
    "\n",
    "    # Remove the book itself from the recommendation\n",
    "    similar_books = similar_books[similar_books.index != isbn]\n",
    "\n",
    "    # Get the top N similar books\n",
    "    top_similar_books = similar_books.head(num_recommendations).index.tolist()\n",
    "\n",
    "    # Get book titles and image URLs\n",
    "    recommended_books_info = [get_book_info(book_isbn, books_df) for book_isbn in top_similar_books]\n",
    "\n",
    "    return recommended_books_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92534324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a3fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
